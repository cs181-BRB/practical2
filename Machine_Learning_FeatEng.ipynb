{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This file provides starter code for extracting features from the xml files and\n",
    "## for doing some learning.\n",
    "##\n",
    "## The basic set-up: \n",
    "## ----------------\n",
    "## main() will run code to extract features, learn, and make predictions.\n",
    "## \n",
    "## extract_feats() is called by main(), and it will iterate through the \n",
    "## train/test directories and parse each xml file into an xml.etree.ElementTree, \n",
    "## which is a standard python object used to represent an xml file in memory.\n",
    "## (More information about xml.etree.ElementTree objects can be found here:\n",
    "## http://docs.python.org/2/library/xml.etree.elementtree.html\n",
    "## and here: http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/)\n",
    "## It will then use a series of \"feature-functions\" that you will write/modify\n",
    "## in order to extract dictionaries of features from each ElementTree object.\n",
    "## Finally, it will produce an N x D sparse design matrix containing the union\n",
    "## of the features contained in the dictionaries produced by your \"feature-functions.\"\n",
    "## This matrix can then be plugged into your learning algorithm.\n",
    "##\n",
    "## The learning and prediction parts of main() are largely left to you, though\n",
    "## it does contain code that randomly picks class-specific weights and predicts\n",
    "## the class with the weights that give the highest score. If your prediction\n",
    "## algorithm involves class-specific weights, you should, of course, learn \n",
    "## these class-specific weights in a more intelligent way.\n",
    "##\n",
    "## Feature-functions:\n",
    "## --------------------\n",
    "## \"feature-functions\" are functions that take an ElementTree object representing\n",
    "## an xml file (which contains, among other things, the sequence of system calls a\n",
    "## piece of potential malware has made), and returns a dictionary mapping feature names to \n",
    "## their respective numeric values. \n",
    "## For instance, a simple feature-function might map a system call history to the\n",
    "## dictionary {'first_call-load_image': 1}. This is a boolean feature indicating\n",
    "## whether the first system call made by the executable was 'load_image'. \n",
    "## Real-valued or count-based features can of course also be defined in this way. \n",
    "## Because this feature-function will be run over ElementTree objects for each \n",
    "## software execution history instance, we will have the (different)\n",
    "## feature values of this feature for each history, and these values will make up \n",
    "## one of the columns in our final design matrix.\n",
    "## Of course, multiple features can be defined within a single dictionary, and in\n",
    "## the end all the dictionaries returned by feature functions (for a particular\n",
    "## training example) will be unioned, so we can collect all the feature values \n",
    "## associated with that particular instance.\n",
    "##\n",
    "## Two example feature-functions, first_last_system_call_feats() and \n",
    "## system_call_count_feats(), are defined below.\n",
    "## The first of these functions indicates what the first and last system-calls \n",
    "## made by an executable are, and the second records the total number of system\n",
    "## calls made by an executable.\n",
    "##\n",
    "## What you need to do:\n",
    "## --------------------\n",
    "## 1. Write new feature-functions (or modify the example feature-functions) to\n",
    "## extract useful features for this prediction task.\n",
    "## 2. Implement an algorithm to learn from the design matrix produced, and to\n",
    "## make predictions on unseen data. Naive code for these two steps is provided\n",
    "## below, and marked by TODOs.\n",
    "##\n",
    "## Computational Caveat\n",
    "## --------------------\n",
    "## Because the biggest of any of the xml files is only around 35MB, the code below \n",
    "## will parse an entire xml file and store it in memory, compute features, and\n",
    "## then get rid of it before parsing the next one. Storing the biggest of the files \n",
    "## in memory should require at most 200MB or so, which should be no problem for\n",
    "## reasonably modern laptops. If this is too much, however, you can lower the\n",
    "## memory requirement by using ElementTree.iterparse(), which does parsing in\n",
    "## a streaming way. See http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/\n",
    "## for an example. \n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import util\n",
    "\n",
    "\n",
    "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      ffs are a list of feature-functions.\n",
    "      direc is a directory containing xml files (expected to be train or test).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "\n",
    "    returns: \n",
    "      a sparse design matrix, a dict mapping features to column-numbers,\n",
    "      a vector of target classes, and a list of system-call-history ids in order \n",
    "      of their rows in the design matrix.\n",
    "      \n",
    "      Note: the vector of target classes returned will contain the true indices of the\n",
    "      target classes on the training data, but will contain only -1's on the test\n",
    "      data\n",
    "    \"\"\"\n",
    "    fds = [] # list of feature dicts\n",
    "    classes = []\n",
    "    ids = [] \n",
    "#     syscall_to_class = {}\n",
    "#     NUM_FEATS_SYSCALL_LIMIT = 12\n",
    "    for datafile in os.listdir(direc):\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str,clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "        except ValueError:\n",
    "#             print clazz\n",
    "#             print classes\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "        rowfd = {}\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        # accumulate features\n",
    "        [rowfd.update(ff(tree)) for ff in ffs]\n",
    "        #Roger\n",
    "        #print clazz\n",
    "        #print rowfd.keys()\n",
    "#         if len(rowfd.keys()) > 0:\n",
    "#             print clazz\n",
    "        #TODO(rzou): iterate thru keys. See if any keys (syscalls) unique to particular clazz.\n",
    "        # Have a dict of vals class_name or 1. Class_name is first class it's seen in. 1 is if mult classes.\n",
    "#         for syscall in rowfd.keys():\n",
    "#             if syscall not in syscall_to_class:\n",
    "#                 syscall_to_class[syscall] = set([clazz])\n",
    "#             elif syscall_to_class[syscall] == NUM_FEATS_SYSCALL_LIMIT:\n",
    "#                 pass\n",
    "#             elif clazz not in syscall_to_class[syscall]:\n",
    "#                 if len(syscall_to_class[syscall]) == NUM_FEATS_SYSCALL_LIMIT - 1:\n",
    "#                     syscall_to_class[syscall] = NUM_FEATS_SYSCALL_LIMIT\n",
    "#                 else:\n",
    "#                     syscall_to_class[syscall].add(clazz)\n",
    "\n",
    "                \n",
    "        fds.append(rowfd)\n",
    "#     print syscall_to_class\n",
    "#     for k,v in syscall_to_class.iteritems():\n",
    "#         if v != NUM_FEATS_SYSCALL_LIMIT:\n",
    "#             print k,v\n",
    "#     print len(syscall_to_class) # num of keys\n",
    "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
    "    return X, feat_dict, np.array(classes), ids\n",
    "\n",
    "\n",
    "def make_design_mat(fds, global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      fds is a list of feature dicts (one for each row).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "       \n",
    "    returns: \n",
    "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
    "        the union of features defined in any of the fds \n",
    "    \"\"\"\n",
    "    if global_feat_dict is None:\n",
    "        all_feats = set()\n",
    "        [all_feats.update(fd.keys()) for fd in fds]\n",
    "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
    "    else:\n",
    "        feat_dict = global_feat_dict\n",
    "        \n",
    "    cols = []\n",
    "    rows = []\n",
    "    data = []        \n",
    "    for i in xrange(len(fds)):\n",
    "        temp_cols = []\n",
    "        temp_data = []\n",
    "        for feat,val in fds[i].iteritems():\n",
    "            try:\n",
    "                # update temp_cols iff update temp_data\n",
    "                temp_cols.append(feat_dict[feat])\n",
    "                temp_data.append(val)\n",
    "            except KeyError as ex:\n",
    "                if global_feat_dict is not None:\n",
    "                    pass  # new feature in test data; nbd\n",
    "                else:\n",
    "                    raise ex\n",
    "\n",
    "        # all fd's features in the same row\n",
    "        k = len(temp_cols)\n",
    "        cols.extend(temp_cols)\n",
    "        data.extend(temp_data)\n",
    "        rows.extend([i]*k)\n",
    "\n",
    "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
    "   \n",
    "\n",
    "    X = sparse.csr_matrix((np.array(data),\n",
    "                   (np.array(rows), np.array(cols))),\n",
    "                   shape=(len(fds), len(feat_dict)))\n",
    "    return X, feat_dict\n",
    "    \n",
    "\n",
    "## Here are two example feature-functions. They each take an xml.etree.ElementTree object, \n",
    "# (i.e., the result of parsing an xml file) and returns a dictionary mapping \n",
    "# feature-names to numeric values.\n",
    "## TODO: modify these functions, and/or add new ones.\n",
    "def first_last_system_call_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
    "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
    "      (in other words, it returns a dictionary indicating what the first and \n",
    "      last system calls made by an executable were.)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    first = True # is this the first system call\n",
    "    last_call = None # keep track of last call we've seen\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            if first:\n",
    "                c[\"first_call-\"+el.tag] = 1\n",
    "                first = False\n",
    "            last_call = el.tag  # update last call seen\n",
    "            \n",
    "    # finally, mark last call seen\n",
    "    c[\"last_call-\"+last_call] = 1\n",
    "    return c\n",
    "\n",
    "def system_call_count_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
    "      made by an executable (summed over all processes)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            c['num_system_calls'] += 1\n",
    "    return c\n",
    "\n",
    "# not sure if should prioritize counts or uniqueness? Or proportion? Unsure...\n",
    "def specific_system_call_count_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'num_system_calls-x' to the number of x-system_calls\n",
    "      made by an executable (summed over all processes)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            c[\"num_system_calls-\"+el.tag] += 1 # Counter properly handles if not already in\n",
    "            #c[el.tag] += 1 # for when looking for features\n",
    "    return c\n",
    "\n",
    "# checks for existence of canary syscalls. Training data showed the following are canaries:\n",
    "# num_system_calls-vm_mapviewofsection Virut\n",
    "# num_system_calls-enum_services Hupigon\n",
    "# num_system_calls-logon_as_user FraudLoad\n",
    "# num_system_calls-delete_share VB\n",
    "# num_system_calls-set_system_time AutoRun\n",
    "# num_system_calls-get_host_by_addr None\n",
    "# num_system_calls-exit_windows None\n",
    "# num_system_calls-create_process_nt None\n",
    "# num_system_calls-get_userinfo None\n",
    "# num_system_calls-com_createole_object None\n",
    "# num_system_calls-enum_handles None\n",
    "# num_system_calls-accept_socket None\n",
    "# LOL FK I FORGOT I APPENDED THE num_system_calls- PREFIX FML\n",
    "# Found canaries by iterating over all training data and looking for unique calls\n",
    "# below: all functions that don't appear in every function. their absence can be a good indicator.\n",
    "# load_driver set(['Magania', 'None', 'Hupigon', 'Krap', 'Agent'])\n",
    "# get_host_by_addr set(['None'])\n",
    "# create_interface set(['Zbot', 'None', 'Agent'])\n",
    "# enum_items set(['None', 'Agent'])\n",
    "# change_service_config set(['None', 'VB', 'Agent', 'Virut', 'Magania', 'Hupigon'])\n",
    "# exit_windows set(['None'])\n",
    "# enum_modules set(['FraudPack', 'VB', 'Tdss', 'FraudLoad', 'None', 'Agent', 'Zbot', 'Lipler', 'AutoRun', 'Hupigon', 'Krap'])\n",
    "# enum_types set(['Zbot', 'None', 'Agent'])\n",
    "# write_value set(['None', 'Agent', 'Lipler', 'Poison', 'AutoRun', 'Magania'])\n",
    "# unload_driver set(['Magania', 'Krap', 'Agent'])\n",
    "# message set(['VB', 'None', 'Agent', 'Swizzor'])\n",
    "# get_userinfo set(['None'])\n",
    "# create_service set(['None', 'Agent', 'Lipler', 'VB', 'Virut', 'Magania', 'Hupigon', 'Krap'])\n",
    "# move_file set(['None', 'Lipler', 'Tdss', 'Swizzor', 'VB', 'Agent', 'Zbot', 'Virut', 'FraudLoad', 'Magania', 'Hupigon'])\n",
    "# vm_write set(['VB', 'Lipler', 'Tdss', 'Swizzor', 'Agent', 'Poison', 'Zbot', 'Virut', 'AutoRun', 'None', 'Krap'])\n",
    "# create_process_as_user set(['Zbot', 'Tdss'])\n",
    "# create_mailslot set(['None', 'FraudLoad'])\n",
    "# com_createole_object set(['None'])\n",
    "# listen_socket set(['Zbot', 'VB', 'Hupigon', 'None', 'Agent'])\n",
    "# enum_share set(['FraudPack', 'None', 'VB', 'Agent', 'Hupigon', 'Krap'])\n",
    "# vm_mapviewofsection set(['Virut'])\n",
    "# download_file set(['None', 'Swizzor', 'VB', 'Agent', 'Magania', 'Krap'])\n",
    "# delete_share set(['VB'])\n",
    "# logon_as_user set(['FraudLoad'])\n",
    "# set_thread_context set(['None', 'Tdss', 'Agent', 'VB', 'Poison', 'Virut', 'AutoRun', 'Krap'])\n",
    "# create_process_nt set(['None'])\n",
    "# vm_allocate set(['VB', 'Lipler', 'Tdss', 'Swizzor', 'Agent', 'Poison', 'Zbot', 'Virut', 'AutoRun', 'None', 'Krap'])\n",
    "# enum_handles set(['None'])\n",
    "# start_service set(['None', 'Lipler', 'Tdss', 'VB', 'Agent', 'Virut', 'FraudLoad', 'Magania', 'Hupigon', 'Krap'])\n",
    "# create_thread_remote set(['None', 'Lipler', 'Swizzor', 'VB', 'Agent', 'Zbot', 'Poison', 'AutoRun', 'Krap', 'Virut'])\n",
    "# connect set(['FraudPack', 'None', 'Tdss', 'AutoRun', 'VB', 'Lipler', 'Zbot', 'Agent', 'FraudLoad', 'Krap'])\n",
    "# enum_services set(['Hupigon'])\n",
    "# vm_read set(['None', 'Agent', 'VB', 'Lipler', 'Virut', 'Krap'])\n",
    "# delete_service set(['None', 'Hupigon', 'Agent'])\n",
    "# read_section set(['None', 'Lipler'])\n",
    "# set_system_time set(['AutoRun'])\n",
    "# add_netjob set(['VB', 'None'])\n",
    "# control_service set(['None', 'Tdss', 'Agent', 'FraudLoad', 'Magania', 'Hupigon'])\n",
    "# accept_socket set(['None'])\n",
    "# download_file_to_cache set(['None', 'Agent', 'Lipler'])\n",
    "# revert_to_self set(['FraudPack', 'None', 'Tdss', 'Swizzor', 'VB', 'Agent', 'Zbot', 'FraudLoad', 'Krap'])\n",
    "# enum_subtypes set(['None', 'Agent'])\n",
    "# remove_directory set(['FraudPack', 'None', 'Lipler', 'Tdss', 'Swizzor', 'VB', 'Agent', 'Virut', 'Hupigon'])\n",
    "# create_namedpipe set(['None', 'Tdss', 'Agent', 'Zbot', 'FraudLoad', 'Krap'])\n",
    "\n",
    "def has_canary_system_call_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'canary-x' to 1 if a canary syscall was\n",
    "      made by an executable\n",
    "    \"\"\"\n",
    "    canaries = set([\\\n",
    "            \"load_driver\",\n",
    "            \"get_host_by_addr\",\n",
    "            \"create_interface\",\n",
    "            \"enum_items\",\n",
    "            \"change_service_config\",\n",
    "            \"exit_windows\",\n",
    "            \"enum_modules\",\n",
    "            \"enum_types\",\n",
    "            \"write_value\",\n",
    "            \"unload_driver\",\n",
    "            \"message\",\n",
    "            \"get_userinfo\",\n",
    "            \"create_service\",\n",
    "            \"move_file\",\n",
    "            \"vm_write\",\n",
    "            \"create_process_as_user\",\n",
    "            \"create_mailslot\",\n",
    "            \"com_createole_object\",\n",
    "            \"listen_socket\",\n",
    "            \"enum_share\",\n",
    "            \"vm_mapviewofsection\",\n",
    "            \"download_file\",\n",
    "            \"delete_share\",\n",
    "            \"logon_as_user\",\n",
    "            \"set_thread_context\",\n",
    "            \"create_process_nt\",\n",
    "            \"vm_allocate\",\n",
    "            \"enum_handles\",\n",
    "            \"start_service\",\n",
    "            \"create_thread_remote\",\n",
    "            \"connect\",\n",
    "            \"enum_services\",\n",
    "            \"vm_read\",\n",
    "            \"delete_service\",\n",
    "            \"read_section\",\n",
    "            \"set_system_time\",\n",
    "            \"add_netjob\",\n",
    "            \"control_service\",\n",
    "            \"accept_socket\",\n",
    "            \"download_file_to_cache\",\n",
    "            \"revert_to_self\",\n",
    "            \"enum_subtypes\",\n",
    "            \"remove_directory\",\n",
    "            \"create_namedpipe\",                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#             \"get_host_by_addr\",\n",
    "#             \"create_interface\",\n",
    "#             \"enum_items\",\n",
    "#             \"exit_windows\",\n",
    "#             \"enum_types\",\n",
    "#             \"unload_driver\",\n",
    "#             \"message\",\n",
    "#             \"get_userinfo\",\n",
    "#             \"create_process_as_user\",\n",
    "#             \"create_mailslot\",\n",
    "#             \"com_createole_object\",\n",
    "#             \"vm_mapviewofsection\",\n",
    "#             \"delete_share\",\n",
    "#             \"logon_as_user\",\n",
    "#             \"create_process_nt\",\n",
    "#             \"enum_handles\",\n",
    "#             \"enum_services\",\n",
    "#             \"delete_service\",\n",
    "#             \"read_section\",\n",
    "#             \"set_system_time\",\n",
    "#             \"add_netjob\",\n",
    "#             \"accept_socket\",\n",
    "#             \"download_file_to_cache\",\n",
    "#             \"enum_subtypes\",\n",
    "                    \n",
    "                    \n",
    "#         'vm_mapviewofsection',\n",
    "#         'enum_services',\n",
    "#         'logon_as_user',\n",
    "#         'delete_share',\n",
    "#         'set_system_time',\n",
    "#         'get_host_by_addr',\n",
    "#         'exit_windows',\n",
    "#         'create_process_nt',\n",
    "#         'get_userinfo',\n",
    "#         'com_createole_object',\n",
    "#         'enum_handles',\n",
    "#         'accept_socket',\n",
    "    ])\n",
    "    s = set()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section and el.tag in canaries:\n",
    "            s.add('canary-' + el.tag)\n",
    "    return dict.fromkeys(s, 1)\n",
    "    \n",
    "# IN WHICH YOU REALIZE THE STAFF-PROVIDED SKELETON CODE IS WRONG AHHHHHH\n",
    "# 'Magania': 29, 'None': 7, 'Agent': 7. On training data. Really good! Out of maybe 41 Magania cases.\n",
    "def magania_fonts_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'windows-fonts' to 1 if a open_file syscall used srcfile=\"C:\\windows\\fonts\\*\"\n",
    "      made by an executable\n",
    "    Roger note: probably magania?\n",
    "    \"\"\"\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section and el.tag == 'open_file':\n",
    "#             print 'wtfmate open'\n",
    "            key_string = el.get('srcfile')\n",
    "#             print key_string\n",
    "#             if key_string:\n",
    "#                 print key_string\n",
    "            if key_string and key_string[:17].lower() == 'c:\\\\windows\\\\fonts\\\\':\n",
    "                return {'magania_fonts' : 1}\n",
    "        else:\n",
    "#             print el.tag, 'lol'\n",
    "#             print el.tag, in_all_section\n",
    "            if el.tag == 'open_file':\n",
    "#                 print 'seriously wat'\n",
    "#                 print in_all_section\n",
    "                key_string = el.get('srcfile')\n",
    "#                 print key_string\n",
    "                if key_string and key_string[:17].lower() == 'c:\\\\windows\\\\fonts\\\\':\n",
    "                    return {'magania_fonts' : 1}\n",
    "\n",
    "    return {}    \n",
    "    \n",
    "def DO_NOT_USE_query_value_file_extensions_unique_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'extension-x' to 1 if a query_value syscall used key=\"*/.x\"\n",
    "      made by an executable\n",
    "    Roger note: innocent extensions (.ppt, .txt) probably indicates more likely None\n",
    "    \"\"\"\n",
    "    s = set()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section and el.tag == 'query_value':\n",
    "            key_string = el.get('key')\n",
    "            if key_string:\n",
    "                last_backslash_index = key_string.rfind('\\\\') # because backslash is used to escape, there are two\n",
    "                if last_backslash_index != -1 and key_string[last_backslash_index + 1] == '.':\n",
    "                    # if the last thing after backslash is a dot extension, add the extension (w/o dot) to unique set as seen\n",
    "                    # for why not checking membership first, see http://stackoverflow.com/questions/29928634/should-i-check-if-an-item-is-already-in-a-set-before-adding-it/29928674#29928674\n",
    "                    s.add('extension-' + key_string[last_backslash_index + 2:])\n",
    "    return dict.fromkeys(s, 1)\n",
    "\n",
    "def query_value_has_dot_file_extensions_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'has_dot' to 1 if a query_value syscall used key=\"*/.x\"\n",
    "      made by an executable. Generally, tests (showitdammit.csv) show that if there is one, there will be many. Else, none.\n",
    "    Roger note: innocent extensions (.ppt, .txt) probably indicates more likely None\n",
    "    \"\"\"\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section and el.tag == 'query_value':\n",
    "            key_string = el.get('key')\n",
    "            if key_string:\n",
    "                last_backslash_index = key_string.rfind('\\\\') # because backslash is used to escape, there are two\n",
    "                if last_backslash_index != -1 and key_string[last_backslash_index + 1] == '.':\n",
    "                    # if the last thing after backslash is a dot extension, add the extension (w/o dot) to unique set as seen\n",
    "                    # for why not checking membership first, see http://stackoverflow.com/questions/29928634/should-i-check-if-an-item-is-already-in-a-set-before-adding-it/29928674#29928674\n",
    "                    return {'has_dot' : 1}\n",
    "    return {} # empty dict\n",
    "\n",
    "# vm_protect get target= key and use regex to get unique identifier string\n",
    "# example: target=SHELL32.dll.&#x24;1FD852. Grab \"SHELL32\". Stuff after .dll. is sometimes useful, sometimes random stuff.\n",
    "# Basically, if there's a .dll (dunno if need to check for this), grab the string before it\n",
    "def vm_protect_targets_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'target-x' to 1 if a vm_protect syscall used target=\"*.dll.*\"\n",
    "      made by an executable\n",
    "    Roger note: idk if will be effective\n",
    "    \"\"\"\n",
    "    s = set()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section and el.tag == 'vm_protect':\n",
    "            key_string = el.get('target')\n",
    "            if key_string:\n",
    "                first_dll_index = key_string.find('.dll') # find first\n",
    "                if first_dll_index != -1:\n",
    "                    # if the last thing after backslash is a dot extension, add the extension (w/o dot) to unique set as seen\n",
    "                    # for why not checking membership first, see http://stackoverflow.com/questions/29928634/should-i-check-if-an-item-is-already-in-a-set-before-adding-it/29928674#29928674\n",
    "                    s.add('vm_targets-' + key_string[:first_dll_index])\n",
    "    return dict.fromkeys(s, 1)\n",
    "\n",
    "    \n",
    "## The following function does the feature extraction, learning, and prediction\n",
    "def main():\n",
    "    train_dir = \"train\"\n",
    "    test_dir = \"test\"\n",
    "    outputfile = \"mypredictions.csv\"  # feel free to change this or take it as an argument\n",
    "    \n",
    "    # TODO put the names of the feature functions you've defined above in this list\n",
    "    ffs = [first_last_system_call_feats, system_call_count_feats]\n",
    "    \n",
    "    # extract features\n",
    "    print \"extracting training features...\"\n",
    "    X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "    print \"done extracting training features\"\n",
    "    print\n",
    "    \n",
    "    # TODO train here, and learn your classification parameters\n",
    "    print \"learning...\"\n",
    "    learned_W = np.random.random((len(global_feat_dict),len(util.malware_classes)))\n",
    "    print \"done learning\"\n",
    "    print\n",
    "    \n",
    "    # get rid of training data and load test data\n",
    "    del X_train\n",
    "    del t_train\n",
    "    del train_ids\n",
    "    print \"extracting test features...\"\n",
    "    X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "    print \"done extracting test features\"\n",
    "    print\n",
    "    \n",
    "    # TODO make predictions on text data and write them out\n",
    "    print \"making predictions...\"\n",
    "    preds = np.argmax(X_test.dot(learned_W),axis=1)\n",
    "    print \"done making predictions\"\n",
    "    print\n",
    "    \n",
    "    print \"writing predictions...\"\n",
    "    util.write_predictions(preds, test_ids, outputfile)\n",
    "    print \"done!\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "Agent\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "Agent\n",
      "None\n",
      "Magania\n",
      "Magania\n",
      "Agent\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "Agent\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "None\n",
      "Magania\n",
      "Magania\n",
      "Agent\n",
      "Magania\n",
      "Magania\n",
      "None\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "None\n",
      "Magania\n",
      "Magania\n",
      "None\n",
      "Magania\n",
      "Magania\n",
      "Magania\n",
      "None\n",
      "Magania\n",
      "Agent\n",
      "Agent\n",
      "Magania\n",
      "None\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"train\"\n",
    "#train_dir = \"train_small\" # FOR TESTING\n",
    "#train_dir = \"magania\"\n",
    "#train_dir = \"wtfmate\"\n",
    "test_dir = \"test\"\n",
    "outputfile = \"mypredictions.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [#first_last_system_call_feats, system_call_count_feats,\\\n",
    "        #specific_system_call_count_feats,\\\n",
    "        #query_value_has_dot_file_extensions_feats,\\\n",
    "        #vm_protect_targets_feats,\\\n",
    "        #has_canary_system_call_feats,\\\n",
    "        magania_fonts_feats,\\\n",
    "        ]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering TODO Roger to add your input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (31, 0)\t1\n",
      "  (33, 0)\t1\n",
      "  (186, 0)\t1\n",
      "  (241, 0)\t1\n",
      "  (311, 0)\t1\n",
      "  (355, 0)\t1\n",
      "  (424, 0)\t1\n",
      "  (435, 0)\t1\n",
      "  (496, 0)\t1\n",
      "  (600, 0)\t1\n",
      "  (624, 0)\t1\n",
      "  (635, 0)\t1\n",
      "  (649, 0)\t1\n",
      "  (674, 0)\t1\n",
      "  (946, 0)\t1\n",
      "  (1012, 0)\t1\n",
      "  (1022, 0)\t1\n",
      "  (1027, 0)\t1\n",
      "  (1032, 0)\t1\n",
      "  (1312, 0)\t1\n",
      "  (1328, 0)\t1\n",
      "  (1339, 0)\t1\n",
      "  (1613, 0)\t1\n",
      "  (1618, 0)\t1\n",
      "  (1807, 0)\t1\n",
      "  (1858, 0)\t1\n",
      "  (1875, 0)\t1\n",
      "  (2092, 0)\t1\n",
      "  (2124, 0)\t1\n",
      "  (2210, 0)\t1\n",
      "  (2381, 0)\t1\n",
      "  (2480, 0)\t1\n",
      "  (2507, 0)\t1\n",
      "  (2584, 0)\t1\n",
      "  (2688, 0)\t1\n",
      "  (2722, 0)\t1\n",
      "  (2725, 0)\t1\n",
      "  (2743, 0)\t1\n",
      "  (2847, 0)\t1\n",
      "  (2893, 0)\t1\n",
      "  (2955, 0)\t1\n",
      "  (2970, 0)\t1\n",
      "  (3026, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "#print sum(X_train)\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train.todense())#.to_csv('showitdammit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "[ 0.78685897  0.77419355  0.79058442  0.78211382  0.78559738]\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, t_train)\n",
    "print \"Random Forest Classifier\"\n",
    "print cross_val_score(RF, X_train, t_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "[ 0.60737179  0.64193548  0.63311688  0.63739837  0.6710311 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNNB = MultinomialNB()\n",
    "print \"Multinomial NB\"\n",
    "print cross_val_score(MNNB, X_train, t_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MNNB.fit(X_train, t_train)\n",
    "predictions = MNNB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(predictions, t_train):\n",
    "    in_both = [i for i, j in zip(predictions, t_train) if i == j]\n",
    "    print len(in_both) / float(len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "[ 0.52884615  0.18064516  0.27272727  0.55121951  0.04255319]\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(X_train, t_train)\n",
    "print \"SVM Classifier\"\n",
    "print cross_val_score(lin_clf, X_train, t_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3086.000000\n",
       "mean        8.378483\n",
       "std         2.795222\n",
       "min         0.000000\n",
       "25%         8.000000\n",
       "50%         8.000000\n",
       "75%        10.000000\n",
       "max        14.000000\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a8f3f50>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b784c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(df['class'], bins=14)\n",
    "plt.title(\"Distribution of Each Class\")\n",
    "plt.xlabel(\"Class Id\")\n",
    "plt.ylabel(\"Occurences in the Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layer TODO BRIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5422</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>430</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1085</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...    22  23  24  25  26  27  28  29    30  \\\n",
       "0  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   0   1   0   0   643   \n",
       "1  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   1   0   0   0  5422   \n",
       "2  1  0  0  0  0  0  0  1  0  0  ...     0   0   0   0   0   0   0   0    93   \n",
       "3  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   0   1   0   0   430   \n",
       "4  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   0   0   0   0  1085   \n",
       "\n",
       "   class  \n",
       "0      8  \n",
       "1      6  \n",
       "2     12  \n",
       "3      8  \n",
       "4     10  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train.toarray())\n",
    "df['class'] = t_train\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting test features...\n",
      "done extracting test features\n"
     ]
    }
   ],
   "source": [
    "print \"extracting test features...\"\n",
    "X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "print \"done extracting test features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n"
     ]
    }
   ],
   "source": [
    "RF_preds = RF.predict(X_test)\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(RF_preds, test_ids, \"rfpredictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n"
     ]
    }
   ],
   "source": [
    "MNNB_preds = MNNB.predict(X_test)\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(MNNB_preds, test_ids, \"mnnbpredictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n"
     ]
    }
   ],
   "source": [
    "lin_clf_preds = lin_clf.predict(X_test)\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(lin_clf_preds, test_ids, \"svmpredictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
