{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This file provides starter code for extracting features from the xml files and\n",
    "## for doing some learning.\n",
    "##\n",
    "## The basic set-up: \n",
    "## ----------------\n",
    "## main() will run code to extract features, learn, and make predictions.\n",
    "## \n",
    "## extract_feats() is called by main(), and it will iterate through the \n",
    "## train/test directories and parse each xml file into an xml.etree.ElementTree, \n",
    "## which is a standard python object used to represent an xml file in memory.\n",
    "## (More information about xml.etree.ElementTree objects can be found here:\n",
    "## http://docs.python.org/2/library/xml.etree.elementtree.html\n",
    "## and here: http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/)\n",
    "## It will then use a series of \"feature-functions\" that you will write/modify\n",
    "## in order to extract dictionaries of features from each ElementTree object.\n",
    "## Finally, it will produce an N x D sparse design matrix containing the union\n",
    "## of the features contained in the dictionaries produced by your \"feature-functions.\"\n",
    "## This matrix can then be plugged into your learning algorithm.\n",
    "##\n",
    "## The learning and prediction parts of main() are largely left to you, though\n",
    "## it does contain code that randomly picks class-specific weights and predicts\n",
    "## the class with the weights that give the highest score. If your prediction\n",
    "## algorithm involves class-specific weights, you should, of course, learn \n",
    "## these class-specific weights in a more intelligent way.\n",
    "##\n",
    "## Feature-functions:\n",
    "## --------------------\n",
    "## \"feature-functions\" are functions that take an ElementTree object representing\n",
    "## an xml file (which contains, among other things, the sequence of system calls a\n",
    "## piece of potential malware has made), and returns a dictionary mapping feature names to \n",
    "## their respective numeric values. \n",
    "## For instance, a simple feature-function might map a system call history to the\n",
    "## dictionary {'first_call-load_image': 1}. This is a boolean feature indicating\n",
    "## whether the first system call made by the executable was 'load_image'. \n",
    "## Real-valued or count-based features can of course also be defined in this way. \n",
    "## Because this feature-function will be run over ElementTree objects for each \n",
    "## software execution history instance, we will have the (different)\n",
    "## feature values of this feature for each history, and these values will make up \n",
    "## one of the columns in our final design matrix.\n",
    "## Of course, multiple features can be defined within a single dictionary, and in\n",
    "## the end all the dictionaries returned by feature functions (for a particular\n",
    "## training example) will be unioned, so we can collect all the feature values \n",
    "## associated with that particular instance.\n",
    "##\n",
    "## Two example feature-functions, first_last_system_call_feats() and \n",
    "## system_call_count_feats(), are defined below.\n",
    "## The first of these functions indicates what the first and last system-calls \n",
    "## made by an executable are, and the second records the total number of system\n",
    "## calls made by an executable.\n",
    "##\n",
    "## What you need to do:\n",
    "## --------------------\n",
    "## 1. Write new feature-functions (or modify the example feature-functions) to\n",
    "## extract useful features for this prediction task.\n",
    "## 2. Implement an algorithm to learn from the design matrix produced, and to\n",
    "## make predictions on unseen data. Naive code for these two steps is provided\n",
    "## below, and marked by TODOs.\n",
    "##\n",
    "## Computational Caveat\n",
    "## --------------------\n",
    "## Because the biggest of any of the xml files is only around 35MB, the code below \n",
    "## will parse an entire xml file and store it in memory, compute features, and\n",
    "## then get rid of it before parsing the next one. Storing the biggest of the files \n",
    "## in memory should require at most 200MB or so, which should be no problem for\n",
    "## reasonably modern laptops. If this is too much, however, you can lower the\n",
    "## memory requirement by using ElementTree.iterparse(), which does parsing in\n",
    "## a streaming way. See http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/\n",
    "## for an example. \n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import util\n",
    "\n",
    "\n",
    "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      ffs are a list of feature-functions.\n",
    "      direc is a directory containing xml files (expected to be train or test).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "\n",
    "    returns: \n",
    "      a sparse design matrix, a dict mapping features to column-numbers,\n",
    "      a vector of target classes, and a list of system-call-history ids in order \n",
    "      of their rows in the design matrix.\n",
    "      \n",
    "      Note: the vector of target classes returned will contain the true indices of the\n",
    "      target classes on the training data, but will contain only -1's on the test\n",
    "      data\n",
    "    \"\"\"\n",
    "    fds = [] # list of feature dicts\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    for datafile in os.listdir(direc):\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str,clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "        rowfd = {}\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        # accumulate features\n",
    "        [rowfd.update(ff(tree)) for ff in ffs]\n",
    "        fds.append(rowfd)\n",
    "        \n",
    "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
    "    return X, feat_dict, np.array(classes), ids\n",
    "\n",
    "\n",
    "def make_design_mat(fds, global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      fds is a list of feature dicts (one for each row).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "       \n",
    "    returns: \n",
    "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
    "        the union of features defined in any of the fds \n",
    "    \"\"\"\n",
    "    if global_feat_dict is None:\n",
    "        all_feats = set()\n",
    "        [all_feats.update(fd.keys()) for fd in fds]\n",
    "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
    "    else:\n",
    "        feat_dict = global_feat_dict\n",
    "        \n",
    "    cols = []\n",
    "    rows = []\n",
    "    data = []        \n",
    "    for i in xrange(len(fds)):\n",
    "        temp_cols = []\n",
    "        temp_data = []\n",
    "        for feat,val in fds[i].iteritems():\n",
    "            try:\n",
    "                # update temp_cols iff update temp_data\n",
    "                temp_cols.append(feat_dict[feat])\n",
    "                temp_data.append(val)\n",
    "            except KeyError as ex:\n",
    "                if global_feat_dict is not None:\n",
    "                    pass  # new feature in test data; nbd\n",
    "                else:\n",
    "                    raise ex\n",
    "\n",
    "        # all fd's features in the same row\n",
    "        k = len(temp_cols)\n",
    "        cols.extend(temp_cols)\n",
    "        data.extend(temp_data)\n",
    "        rows.extend([i]*k)\n",
    "\n",
    "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
    "   \n",
    "\n",
    "    X = sparse.csr_matrix((np.array(data),\n",
    "                   (np.array(rows), np.array(cols))),\n",
    "                   shape=(len(fds), len(feat_dict)))\n",
    "    return X, feat_dict\n",
    "    \n",
    "\n",
    "## Here are two example feature-functions. They each take an xml.etree.ElementTree object, \n",
    "# (i.e., the result of parsing an xml file) and returns a dictionary mapping \n",
    "# feature-names to numeric values.\n",
    "## TODO: modify these functions, and/or add new ones.\n",
    "def first_last_system_call_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
    "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
    "      (in other words, it returns a dictionary indicating what the first and \n",
    "      last system calls made by an executable were.)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    first = True # is this the first system call\n",
    "    last_call = None # keep track of last call we've seen\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            if first:\n",
    "                c[\"first_call-\"+el.tag] = 1\n",
    "                first = False\n",
    "            last_call = el.tag  # update last call seen\n",
    "            \n",
    "    # finally, mark last call seen\n",
    "    c[\"last_call-\"+last_call] = 1\n",
    "    return c\n",
    "\n",
    "def system_call_count_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
    "      made by an executable (summed over all processes)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            c['num_system_calls'] += 1\n",
    "    return c\n",
    "\n",
    "## The following function does the feature extraction, learning, and prediction\n",
    "def main():\n",
    "    train_dir = \"train\"\n",
    "    test_dir = \"test\"\n",
    "    outputfile = \"mypredictions.csv\"  # feel free to change this or take it as an argument\n",
    "    \n",
    "    # TODO put the names of the feature functions you've defined above in this list\n",
    "    ffs = [first_last_system_call_feats, system_call_count_feats]\n",
    "    \n",
    "    # extract features\n",
    "    print \"extracting training features...\"\n",
    "    X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "    print \"done extracting training features\"\n",
    "    print\n",
    "    \n",
    "    # TODO train here, and learn your classification parameters\n",
    "    print \"learning...\"\n",
    "    learned_W = np.random.random((len(global_feat_dict),len(util.malware_classes)))\n",
    "    print \"done learning\"\n",
    "    print\n",
    "    \n",
    "    # get rid of training data and load test data\n",
    "    del X_train\n",
    "    del t_train\n",
    "    del train_ids\n",
    "    print \"extracting test features...\"\n",
    "    X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "    print \"done extracting test features\"\n",
    "    print\n",
    "    \n",
    "    # TODO make predictions on text data and write them out\n",
    "    print \"making predictions...\"\n",
    "    preds = np.argmax(X_test.dot(learned_W),axis=1)\n",
    "    print \"done making predictions\"\n",
    "    print\n",
    "    \n",
    "    print \"writing predictions...\"\n",
    "    util.write_predictions(preds, test_ids, outputfile)\n",
    "    print \"done!\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "outputfile = \"mypredictions.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [first_last_system_call_feats, system_call_count_feats]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering TODO Roger to add your input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "[ 0.78685897  0.77419355  0.79058442  0.78211382  0.78559738]\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, t_train)\n",
    "print \"Random Forest Classifier\"\n",
    "print cross_val_score(RF, X_train, t_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "[ 0.60737179  0.64193548  0.63311688  0.63739837  0.6710311 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNNB = MultinomialNB()\n",
    "print \"Multinomial NB\"\n",
    "print cross_val_score(MNNB, X_train, t_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MNNB.fit(X_train, t_train)\n",
    "predictions = MNNB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(predictions, t_train):\n",
    "    in_both = [i for i, j in zip(predictions, t_train) if i == j]\n",
    "    print len(in_both) / float(len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "[ 0.52884615  0.18064516  0.27272727  0.55121951  0.04255319]\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(X_train, t_train)\n",
    "print \"SVM Classifier\"\n",
    "print cross_val_score(lin_clf, X_train, t_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3086.000000\n",
       "mean        8.378483\n",
       "std         2.795222\n",
       "min         0.000000\n",
       "25%         8.000000\n",
       "50%         8.000000\n",
       "75%        10.000000\n",
       "max        14.000000\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a8f3f50>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b784c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(df['class'], bins=14)\n",
    "plt.title(\"Distribution of Each Class\")\n",
    "plt.xlabel(\"Class Id\")\n",
    "plt.ylabel(\"Occurences in the Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layer TODO BRIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5422</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>430</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1085</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...    22  23  24  25  26  27  28  29    30  \\\n",
       "0  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   0   1   0   0   643   \n",
       "1  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   1   0   0   0  5422   \n",
       "2  1  0  0  0  0  0  0  1  0  0  ...     0   0   0   0   0   0   0   0    93   \n",
       "3  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   0   1   0   0   430   \n",
       "4  1  0  0  0  0  0  0  0  0  0  ...     0   0   0   0   0   0   0   0  1085   \n",
       "\n",
       "   class  \n",
       "0      8  \n",
       "1      6  \n",
       "2     12  \n",
       "3      8  \n",
       "4     10  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train.toarray())\n",
    "df['class'] = t_train\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting test features...\n",
      "done extracting test features\n"
     ]
    }
   ],
   "source": [
    "print \"extracting test features...\"\n",
    "X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "print \"done extracting test features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n"
     ]
    }
   ],
   "source": [
    "RF_preds = RF.predict(X_test)\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(RF_preds, test_ids, \"rfpredictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n"
     ]
    }
   ],
   "source": [
    "MNNB_preds = MNNB.predict(X_test)\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(MNNB_preds, test_ids, \"mnnbpredictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n"
     ]
    }
   ],
   "source": [
    "lin_clf_preds = lin_clf.predict(X_test)\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(lin_clf_preds, test_ids, \"svmpredictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
